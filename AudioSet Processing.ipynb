{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective** Read the AudioSet data and convert it into a usable JSON format file.\n",
    "\n",
    "**Prerequisite**: Download the data from [AudioSet](https://research.google.com/audioset/download.html) and uncompress the `tar.gz` file. Make sure this notebook is in the same directory as the uncompressed embeddings folder that is generated `audioset_v1_embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"audioset_v1_embeddings/eval\"\n",
    "\n",
    "dataset = []\n",
    "for file_name in os.listdir(directory):\n",
    "     if file_name.endswith(\".tfrecord\"):\n",
    "            dataset.append(os.path.join(directory,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = pd.read_csv('class_labels_indices.csv')\n",
    "labels = class_labels['display_name'].tolist()\n",
    "\n",
    "music_class = class_labels[class_labels['display_name'].str.contains('Music', case=False)]\n",
    "music_labels = music_class['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100th file ...\n",
      "Processing 200th file ...\n",
      "Processing 300th file ...\n",
      "Processing 400th file ...\n",
      "Processing 500th file ...\n",
      "Processing 600th file ...\n",
      "Processing 700th file ...\n",
      "Processing 800th file ...\n",
      "Processing 900th file ...\n",
      "Processing 1000th file ...\n",
      "Processing 1100th file ...\n",
      "Processing 1200th file ...\n",
      "Processing 1300th file ...\n",
      "Processing 1400th file ...\n",
      "Processing 1500th file ...\n",
      "Processing 1600th file ...\n",
      "Processing 1700th file ...\n",
      "Processing 1800th file ...\n",
      "Processing 1900th file ...\n",
      "Processing 2000th file ...\n"
     ]
    }
   ],
   "source": [
    "audios = []\n",
    "counter = 0\n",
    "NUM_SECONDS = 10\n",
    "\n",
    "for raw_record in raw_dataset:\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    \n",
    "    # Audio Meta data\n",
    "    audio_labels = example.context.feature['labels'].int64_list.value\n",
    "    start_time = example.context.feature['start_time_seconds'].float_list.value\n",
    "    end_time = example.context.feature['end_time_seconds'].float_list.value\n",
    "    video_id = example.context.feature['video_id'].bytes_list.value\n",
    "    \n",
    "    if not (set(music_labels) & set(audio_labels)):\n",
    "        continue\n",
    "\n",
    "    # Audio Feature\n",
    "    feature_list = example.feature_lists.feature_list['audio_embedding'].feature\n",
    "    final_features = [list(feature.bytes_list.value[0]) for feature in feature_list]\n",
    "    audio_embedding = [item for sublist in final_features[:NUM_SECONDS] for item in sublist]\n",
    "    \n",
    "    if len(final_features) < NUM_SECONDS:\n",
    "        continue\n",
    "    \n",
    "    audio = {\n",
    "        'label': audio_labels,\n",
    "        'video_id': video_id[0],\n",
    "        'start_time': start_time[0],\n",
    "        'end_time': end_time[0],\n",
    "        'data': audio_embedding\n",
    "    }\n",
    "    \n",
    "    audios.append(audio)\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"Processing {counter}th file ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('music_set.json', 'w') as file:\n",
    "    str_audio = repr(audios)\n",
    "    json.dump(str_audio, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 255, 0, 255, 147, 255, 12, 255, 0, 0],\n",
       " [166, 73, 135, 117, 139, 31, 187, 200, 190, 99],\n",
       " [71, 24, 175, 143, 68, 126, 84, 118, 78, 157],\n",
       " [208, 255, 255, 68, 8, 145, 134, 220, 50, 205]]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[audio['data'][:10] for audio in audios[:4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "How to read from `tfrecord` files: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#scrollTo=nsEAACHcnm3f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
